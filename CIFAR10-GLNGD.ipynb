{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15898d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf \n",
    "# Common imports\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import itertools\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.keras import backend_config\n",
    "from tensorflow.python.keras.optimizer_v2 import learning_rate_schedule\n",
    "from tensorflow.python.keras.optimizer_v2 import optimizer_v2\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import state_ops\n",
    "from tensorflow.python.ops import variables as tf_variables\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "import scipy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2869fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter(n):\n",
    "    alpha = []\n",
    "    for i in range(n):\n",
    "    \talpha.append(4.8 + 0.005**(i+1)) #0.8 \n",
    "    return alpha\n",
    "\n",
    "def parameter1(n):\n",
    "    alpha = []\n",
    "    for i in range(n):\n",
    "        alpha.append(1.4 - 0.005**(i+1)) # 0.8\n",
    "    beta = []\n",
    "    for i in range(n):\n",
    "        beta.append(0.9 - 0.005**(i+1)) #0.8\n",
    "    return alpha, beta\n",
    "\n",
    "def summation(n):\n",
    "    summ = 0\n",
    "    alpha = parameter(n)\n",
    "    for i in range(n):\n",
    "        summ += alpha[i]\n",
    "    return summ\n",
    "\n",
    "def Fisher(n):\n",
    "    FIM = []\n",
    "    alpha = parameter(n)\n",
    "    for i in range(n):\n",
    "        Row = []\n",
    "        for j in range(n):\n",
    "            if i == j: \n",
    "                Row.append(special.polygamma(1, alpha[i]) - special.polygamma(1, summation(n)))\n",
    "            else:\n",
    "                Row.append(- special.polygamma(1, summation(n)))\n",
    "        FIM.append(Row)\n",
    "    FIM = numpy.array(FIM)\n",
    "    FIM = numpy.linalg.inv(FIM)\n",
    "    return FIM\n",
    "\n",
    "def Fisher2(n):\n",
    "    FIM = []\n",
    "    for i in range(n):\n",
    "        Zero = []\n",
    "        for j in range(n):\n",
    "            Zero.append(0)\n",
    "        FIM.append(Zero)\n",
    "    alpha, beta = parameter1(n)\n",
    "    for i in range(0,n,2):\n",
    "        FIM[i][i] = special.polygamma(1, alpha[i]) - special.polygamma(1, alpha[i]+beta[i])\n",
    "        FIM[i+1][i] = - special.polygamma(1, alpha[i]+beta[i])\n",
    "        FIM[i][i+1] = - special.polygamma(1, alpha[i]+beta[i])\n",
    "        FIM[i+1][i+1] = special.polygamma(1, beta[i]) - special.polygamma(1, alpha[i]+beta[i])\n",
    "    FIM = numpy.array(FIM)\n",
    "    FIM = numpy.linalg.inv(FIM)\n",
    "    return FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47aa37eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grunwald_Letnikov_derivative(gradient, h, alpha, kappa, variable):\n",
    "    GL_gradient = np.array([])\n",
    "    for i in range(len(gradient)):\n",
    "        summ = 0\n",
    "        for j in range(len(gradient)):\n",
    "            summ += (-1)**k * scipy.special.gamma(alpha+1)*variable[j]/(scipy.special.gamma(kappa+1)*scipy.special.gamma(alpha-kappa+1))\n",
    "        GL_gradient.append(\n",
    "            1/h**alpha * summ\n",
    "        ) \n",
    "    return GL_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d723c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLFGD(optimizer_v2.OptimizerV2):\n",
    "  _HAS_AGGREGATE_GRAD = True\n",
    "\n",
    "  def __init__(self,\n",
    "               learning_rate=0.01,\n",
    "               momentum=0.0,\n",
    "               nesterov=False,\n",
    "               name=\"GLFGD\",\n",
    "               **kwargs):\n",
    "    super(GLFGD, self).__init__(name, **kwargs)\n",
    "    self._set_hyper(\"learning_rate\", kwargs.get(\"lr\", learning_rate))\n",
    "    self._set_hyper(\"decay\", self._initial_decay)\n",
    "\n",
    "    self._momentum = False\n",
    "    if isinstance(momentum, tf.Tensor) or callable(momentum) or momentum > 0:\n",
    "      self._momentum = True\n",
    "    if isinstance(momentum, (int, float)) and (momentum < 0 or momentum > 1):\n",
    "      raise ValueError(f\"`momentum` must be between [0, 1]. Received: \"\n",
    "                       f\"momentum={momentum} (of type {type(momentum)}).\")\n",
    "    self._set_hyper(\"momentum\", momentum)\n",
    "\n",
    "    self.nesterov = nesterov\n",
    "\n",
    "  def _create_slots(self, var_list):\n",
    "    if self._momentum:\n",
    "      for var in var_list:\n",
    "        self.add_slot(var, \"momentum\")\n",
    "\n",
    "  def _prepare_local(self, var_device, var_dtype, apply_state):\n",
    "    super(GLFGD, self)._prepare_local(var_device, var_dtype, apply_state)\n",
    "    apply_state[(var_device, var_dtype)][\"momentum\"] = tf.identity(\n",
    "        self._get_hyper(\"momentum\", var_dtype))\n",
    "\n",
    "  def _resource_apply_dense(self, grad, var, apply_state=None):\n",
    "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
    "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
    "                    or self._fallback_apply_state(var_device, var_dtype))\n",
    "\n",
    "    if self._momentum:\n",
    "      momentum_var = self.get_slot(var, \"momentum\")\n",
    "      return tf.raw_ops.ResourceApplyKerasMomentum(\n",
    "          var=var.handle,\n",
    "          accum=momentum_var.handle,\n",
    "          lr=coefficients[\"lr_t\"],\n",
    "          grad=grad,\n",
    "          momentum=coefficients[\"momentum\"],\n",
    "          use_locking=self._use_locking,\n",
    "          use_nesterov=self.nesterov)\n",
    "    else:\n",
    "      return tf.raw_ops.ResourceApplyGradientDescent(\n",
    "          var=var.handle,\n",
    "          alpha=coefficients[\"lr_t\"],\n",
    "          delta=grad,\n",
    "          use_locking=self._use_locking)\n",
    "\n",
    "  def _resource_apply_sparse_duplicate_indices(self, grad, var, indices,\n",
    "                                               **kwargs):\n",
    "    if self._momentum:\n",
    "      return super(GLFGD, self)._resource_apply_sparse_duplicate_indices(\n",
    "          grad, var, indices, **kwargs)\n",
    "    else:\n",
    "      var_device, var_dtype = var.device, var.dtype.base_dtype\n",
    "      coefficients = (kwargs.get(\"apply_state\", {}).get((var_device, var_dtype))\n",
    "                      or self._fallback_apply_state(var_device, var_dtype))\n",
    "\n",
    "      return tf.raw_ops.ResourceScatterAdd(\n",
    "          resource=var.handle,\n",
    "          indices=indices,\n",
    "          #updates=-Grunwald_Letnikov_derivative(grad, 0.01, 6.8, 4, var) * coefficients[\"lr_t\"])\n",
    "          updates=np.dot(Fisher(len(grad)),Grunwald_Letnikov_derivative(grad, 0.001, 2, 1.5, var).transpose()) * coefficients[\"lr_t\"])          \n",
    "          #updates=-grad * coefficients[\"lr_t\"])\n",
    "\n",
    "  def _resource_apply_sparse(self, grad, var, indices, apply_state=None):\n",
    "    # This method is only needed for momentum optimization.\n",
    "    var_device, var_dtype = var.device, var.dtype.base_dtype\n",
    "    coefficients = ((apply_state or {}).get((var_device, var_dtype))\n",
    "                    or self._fallback_apply_state(var_device, var_dtype))\n",
    "\n",
    "    momentum_var = self.get_slot(var, \"momentum\")\n",
    "    return tf.raw_ops.ResourceSparseApplyKerasMomentum(\n",
    "        var=var.handle,\n",
    "        accum=momentum_var.handle,\n",
    "        lr=coefficients[\"lr_t\"],\n",
    "        grad=grad,\n",
    "        indices=indices,\n",
    "        momentum=coefficients[\"momentum\"],\n",
    "        use_locking=self._use_locking,\n",
    "        use_nesterov=self.nesterov)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = super(GLFGD, self).get_config()\n",
    "    config.update({\n",
    "        \"learning_rate\": self._serialize_hyperparameter(\"learning_rate\"),\n",
    "        \"decay\": self._initial_decay,\n",
    "        \"momentum\": self._serialize_hyperparameter(\"momentum\"),\n",
    "        \"nesterov\": self.nesterov,\n",
    "    })\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45fa9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aab0741",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a2c60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pliak\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[Text(0, 0, 'airplane'),\n",
       "  Text(1, 0, 'automobile'),\n",
       "  Text(2, 0, 'bird'),\n",
       "  Text(3, 0, 'cat'),\n",
       "  Text(4, 0, 'deer'),\n",
       "  Text(5, 0, 'dog'),\n",
       "  Text(6, 0, 'frog'),\n",
       "  Text(7, 0, 'horse'),\n",
       "  Text(8, 0, 'ship'),\n",
       "  Text(9, 0, 'truck')]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAGbCAYAAAB09LxeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeCElEQVR4nO3df9RtdV0n8PdHMCWVRLk6BBrmMJM/mnQgQq2JtJWMpVAjRpNBZUOaps1ks3RqNYwzNLb6MaWmiY4BmmNkmWRjapRapuJFUX5FssSUZABNC7Uo8DN/nO+Vw+W59z7APff5Ps99vdY66+zzPXvv8/k+Z+993s/+cU51dwAAmM/dNroAAADWJqgBAExKUAMAmJSgBgAwKUENAGBSB250Aaty6KGH9pFHHrnRZQAA7NFFF1306e7etnP7lg1qRx55ZLZv377RZQAA7FFV/dVa7Q59AgBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKRWGtSq6uNVdUlVXVxV20fb/arqHVX10XF/yNL4L6yqq6rqyqp64lL70WM+V1XVS6qqVlk3AMAM9sUetW/r7kd19zHj8QuSXNDdRyW5YDxOVT08ySlJHpHkhCQvr6oDxjSvSHJ6kqPG7YR9UDcAwIbaiEOfJyY5Zwyfk+SkpfY3dPdN3X11kquSHFtVhyU5uLvf292d5NylaQAAtqwDVzz/TvL2quokr+zus5I8sLuvTZLuvraqHjDGPTzJ+5amvWa0/dMY3rn9dqrq9Cz2vOXBD37w7Z4/+qfOvUud2QgX/cKp6x73Ey/6+hVWshoP/tlL1j3u4176uBVWshrv+fH3rHvcd/2bb11hJXvft777Xese92U/+fsrrGQ1nvNLT173uGc+/akrrGQ1fvp1b1z3uFec+ccrrGQ1HvbTj1/3uGecccbqClmRO1Lzeb997OoKWYGnnXzhusf9hje+bYWVrMaHn/rEPY+0ZNVB7XHd/akRxt5RVX+xm3HXOu+sd9N++8ZFEDwrSY455pg1xwEA2CxWeuizuz817q9P8qYkxya5bhzOzLi/fox+TZIHLU1+RJJPjfYj1mgHANjSVhbUqupeVXWfHcNJviPJpUnOT3LaGO20JG8ew+cnOaWq7lFVD8niooELx2HSG6vquHG156lL0wAAbFmrPPT5wCRvGt+kcWCS13f3H1bVB5KcV1XPSPKJJCcnSXdfVlXnJbk8yc1Jnt3dt4x5PSvJ2UkOSvLWcQMA2NJWFtS6+2NJvmGN9s8kecIupjkzyZlrtG9P8si9XSMAwMz8MgEAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUisPalV1QFV9qKreMh7fr6reUVUfHfeHLI37wqq6qqqurKonLrUfXVWXjOdeUlW16roBADbavtij9rwkVyw9fkGSC7r7qCQXjMepqocnOSXJI5KckOTlVXXAmOYVSU5PctS4nbAP6gYA2FArDWpVdUSS70zy6qXmE5OcM4bPSXLSUvsbuvum7r46yVVJjq2qw5Ic3N3v7e5Ocu7SNAAAW9aq96j9SpL/nORLS20P7O5rk2TcP2C0H57kk0vjXTPaDh/DO7ffTlWdXlXbq2r7DTfcsFc6AACwUVYW1Krqu5Jc390XrXeSNdp6N+23b+w+q7uP6e5jtm3bts6XBQCY04ErnPfjkjylqp6U5J5JDq6q1yW5rqoO6+5rx2HN68f41yR50NL0RyT51Gg/Yo12AIAtbWV71Lr7hd19RHcfmcVFAn/c3U9Pcn6S08ZopyV58xg+P8kpVXWPqnpIFhcNXDgOj95YVceNqz1PXZoGAGDLWuUetV15cZLzquoZST6R5OQk6e7Lquq8JJcnuTnJs7v7ljHNs5KcneSgJG8dNwCALW2fBLXufmeSd47hzyR5wi7GOzPJmWu0b0/yyNVVCAAwH79MAAAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMamVBraruWVUXVtWHq+qyqvpvo/1+VfWOqvrouD9kaZoXVtVVVXVlVT1xqf3oqrpkPPeSqqpV1Q0AMItV7lG7Kcnju/sbkjwqyQlVdVySFyS5oLuPSnLBeJyqeniSU5I8IskJSV5eVQeMeb0iyelJjhq3E1ZYNwDAFFYW1Hrh8+Ph3cetk5yY5JzRfk6Sk8bwiUne0N03dffVSa5KcmxVHZbk4O5+b3d3knOXpgEA2LJWeo5aVR1QVRcnuT7JO7r7/Uke2N3XJsm4f8AY/fAkn1ya/JrRdvgY3rl9rdc7vaq2V9X2G264Ya/2BQBgX1tpUOvuW7r7UUmOyGLv2CN3M/pa5531btrXer2zuvuY7j5m27Ztd7heAICZ7JOrPrv7c0nemcW5ZdeNw5kZ99eP0a5J8qClyY5I8qnRfsQa7QAAW9oqr/rcVlX3HcMHJfn2JH+R5Pwkp43RTkvy5jF8fpJTquoeVfWQLC4auHAcHr2xqo4bV3ueujQNAMCWdeAK531YknPGlZt3S3Jed7+lqt6b5LyqekaSTyQ5OUm6+7KqOi/J5UluTvLs7r5lzOtZSc5OclCSt44bAMCWtrKg1t0fSfLoNdo/k+QJu5jmzCRnrtG+Pcnuzm8DANhy/DIBAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTWldQq6oL1tMGAMDes9sfZa+qeyb5yiSHVtUhSWo8dXCSr15xbQAA+7XdBrUkP5rkJ7IIZRfl1qD2d0l+bXVlAQCw26DW3b+a5Fer6se7+6X7qCYAALLnPWpJku5+aVU9NsmRy9N097krqgsAYL+3rqBWVa9N8tAkFye5ZTR3EkENAGBF1hXUkhyT5OHd3assBgCAW633e9QuTfLPVlkIAAC3td49aocmubyqLkxy047G7n7KSqoCAGDdQe2MVRYBAMDtrfeqz3etuhAAAG5rvVd93pjFVZ5J8hVJ7p7kC9198KoKAwDY3613j9p9lh9X1UlJjl1FQQAALKz3qs/b6O7fS/L4vVsKAADL1nvo83uWHt4ti+9V851qAAArtN6rPp+8NHxzko8nOXGvVwMAwJet9xy1H1p1IQAA3Na6zlGrqiOq6k1VdX1VXVdVv1NVR6y6OACA/dl6Lyb4jSTnJ/nqJIcn+f3RBgDAiqw3qG3r7t/o7pvH7ewk21ZYFwDAfm+9Qe3TVfX0qjpg3J6e5DOrLAwAYH+33qD2w0meluT/Jbk2yVOTuMAAAGCF1vv1HP89yWnd/dkkqar7JfnFLAIcAAArsN49av9qR0hLku7+mySPXk1JAAAk6w9qd6uqQ3Y8GHvU1rs3DgCAO2G9YeuXkvx5Vb0xi5+OelqSM1dWFQAA6/5lgnOransWP8ReSb6nuy9faWUAAPu5dR++HMFMOAMA2EfWe44aAAD7mKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCY1MqCWlU9qKr+pKquqKrLqup5o/1+VfWOqvrouD9kaZoXVtVVVXVlVT1xqf3oqrpkPPeSqqpV1Q0AMItV7lG7OclPdvfDkhyX5NlV9fAkL0hyQXcfleSC8TjjuVOSPCLJCUleXlUHjHm9IsnpSY4atxNWWDcAwBRWFtS6+9ru/uAYvjHJFUkOT3JiknPGaOckOWkMn5jkDd19U3dfneSqJMdW1WFJDu7u93Z3Jzl3aRoAgC1rn5yjVlVHJnl0kvcneWB3X5sswlySB4zRDk/yyaXJrhlth4/hndvXep3Tq2p7VW2/4YYb9mofAAD2tZUHtaq6d5LfSfIT3f13uxt1jbbeTfvtG7vP6u5juvuYbdu23fFiAQAmstKgVlV3zyKk/WZ3/+5ovm4czsy4v360X5PkQUuTH5HkU6P9iDXaAQC2tFVe9VlJ/neSK7r7l5eeOj/JaWP4tCRvXmo/paruUVUPyeKigQvH4dEbq+q4Mc9Tl6YBANiyDlzhvB+X5AeSXFJVF4+2/5LkxUnOq6pnJPlEkpOTpLsvq6rzklyexRWjz+7uW8Z0z0pydpKDkrx13AAAtrSVBbXu/rOsfX5ZkjxhF9OcmeTMNdq3J3nk3qsOAGB+fpkAAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJjUyoJaVb2mqq6vqkuX2u5XVe+oqo+O+0OWnnthVV1VVVdW1ROX2o+uqkvGcy+pqlpVzQAAM1nlHrWzk5ywU9sLklzQ3UcluWA8TlU9PMkpSR4xpnl5VR0wpnlFktOTHDVuO88TAGBLWllQ6+53J/mbnZpPTHLOGD4nyUlL7W/o7pu6++okVyU5tqoOS3Jwd7+3uzvJuUvTAABsafv6HLUHdve1STLuHzDaD0/yyaXxrhlth4/hndvXVFWnV9X2qtp+ww037NXCAQD2tVkuJljrvLPeTfuauvus7j6mu4/Ztm3bXisOAGAj7Ougdt04nJlxf/1ovybJg5bGOyLJp0b7EWu0AwBsefs6qJ2f5LQxfFqSNy+1n1JV96iqh2Rx0cCF4/DojVV13Lja89SlaQAAtrQDVzXjqvo/SY5PcmhVXZPkvyZ5cZLzquoZST6R5OQk6e7Lquq8JJcnuTnJs7v7ljGrZ2VxBelBSd46bgAAW97Kglp3f98unnrCLsY/M8mZa7RvT/LIvVgaAMCmMMvFBAAA7ERQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmJagBAExKUAMAmJSgBgAwKUENAGBSghoAwKQENQCASQlqAACTEtQAACYlqAEATEpQAwCYlKAGADApQQ0AYFKCGgDApAQ1AIBJCWoAAJMS1AAAJiWoAQBMSlADAJiUoAYAMClBDQBgUoIaAMCkBDUAgEkJagAAkxLUAAAmtWmCWlWdUFVXVtVVVfWCja4HAGDVNkVQq6oDkvxakn+b5OFJvq+qHr6xVQEArNamCGpJjk1yVXd/rLv/Mckbkpy4wTUBAKxUdfdG17BHVfXUJCd094+Mxz+Q5Ju6+zk7jXd6ktPHw3+Z5Mp9WOahST69D19vX9rKfUv0b7PTv81rK/ct0b/Nbl/372u6e9vOjQfuwwLuilqj7XYJs7vPSnLW6su5vara3t3HbMRrr9pW7luif5ud/m1eW7lvif5tdrP0b7Mc+rwmyYOWHh+R5FMbVAsAwD6xWYLaB5IcVVUPqaqvSHJKkvM3uCYAgJXaFIc+u/vmqnpOkrclOSDJa7r7sg0ua2cbcsh1H9nKfUv0b7PTv81rK/ct0b/Nbor+bYqLCQAA9keb5dAnAMB+R1ADAJiUoLaTqvq/VXXfOzjN2eO73qZVVSet+tccqurIqrp0F8+9esfrV9XHq+rQVdayp5qW69nD9D9YVS9bTXUbo6qOr6rHbnQdd0RVnVFVz9/oOlZtq/Wzqp5bVVdU1W9udC131e62b/uDXW23q+opm+FnHavqvlX1Y3tpXsdX1Vv2xrzWQ1DbSXc/qbs/t9xWC5v9b3VSFj+/tSG6+0e6+/KNev2d7aqe8XNlW93xSTZVUNsbqmpTXDy1xfxYkid19/fvaNgf34et3OfuPr+7X7zRdazDfbNYHm9jM2zzN3v4uEuq6veq6qKqumz8qsGX/2sY/z1dUVUvT/LBJA+qqs9X1S9V1Qer6oKqut03CFfVz1bVB6rq0qo6q6pqtL+zqn6+qi6sqr+sqm8Z7QdU1S+MaT5SVT96F+v//NLzTx17+x6b5ClJfqGqLq6qh1bVo6rqfeM131RVhyzV+b+q6t2j/99YVb9bVR+tqv+xNO//NPp4aVX9xFJZB1bVOWO+b6yqr1ya7+2+OLCqnj7+JhdX1StXtNLcrqblesb7+qKqen+Sx1TVD4336F1JHreCelaiqk4dffxwVb22qp5cVe+vqg9V1R9V1QOr6sgkz0zyH8ff/Fs2uOxdqqqfrqorq+qPsvilkYxl9w/Hcv+nVfV1o31bVf3OWI8+UFWPG+1njPXw7UnO3bje7Nou+rmr9fMbR9t7x3Zj2j08VfXrSb42yflV9bfL70NVfc3Yhn5k3D94TPPQ0e8PjHXy87t9kX3vgKp61djmvr2qDtrDtvTnxnbkeVV18thefriq3j3GudPb/1WqqntV1R+MWi+tqu8dT/14LT7/Llla97581KEWnze/PtbNv6yq79qwTtzei5M8dGz3PlBVf1JVr09ySe20t7Sqnl9VZ4zhfz62nx8efX/o8kzHOvmhqvralVXe3fvtLcn9xv1BSS5Ncv8kH8/iZyOOTPKlJMctjd9Jvn8M/2ySl43hs5M8dXmeY/i1SZ48ht+Z5JfG8JOS/NEYPj3Jz4zheyTZnuQhd6H+zy89/9QkZ+9c43j8kSTfOoZflORXlur8+TH8vCy+WPiwUds14zWOTnJJknsluXeSy5I8evzNOsnjxvSvSfL8pfkeM4Z3/I0fluT3k9x9tL88yal7+T1es6ad6ukkTxvDhyX5RJJtSb4iyXt2vM8z35I8IoufTDt0x7KR5JDcemX3jywtf2fseF9mvS0tY1+Z5OAkV4337YIkR41xvinJH4/h1yf55jH84CRXLPX1oiQHbXSf7mA/d7V+XprksWP4xUku3eg+7KF/O9b127wPY70/bQz/cJLfG8NvSfJ9Y/iZWdqebfRtbEtuTvKo8fi8JE/fzXv1ziQvX5r+kiSHj+H7jvs7vf1fcV//XZJXLT3+qvFe/vh4/GNJXj2GfzC3/Sz8wyx2Ah2VxWfGPTe6P0vv36Vj+PgkX9jxt15+bjx+fpIzxvD7k3z3GL7nWFePH8vqY8dy/eBV1r5f71FL8tyq+nCS92XxywdH7fT8X3X3+5YefynJb43h1yX55jXm+W1jL8YlSR6fxQfoDr877i/KYsFIku9IcmpVXZzFAnH/Neq4s/Wvqaq+KosNxbtG0zlJ/s3SKDu+TPiSJJd197XdfVOSj43X+eYkb+ruL3T350e/duyZ+WR3v2cM7+pvtMMTsvig+sDo/xOy+A98b9tTTbck+Z0x/E1J3tndN3T3P+bW93t2j0/yxu7+dJJ0999k8QsebxvL4k/ltsvi7L4li2Xsi939d1ksk/fMYsP422N5eWUWwTpJvj3Jy0b7+UkOrqr7jOfO7+6/35fF3wFr9fNeWWP9rMW5s/fp7j8f7a/f59XeNcvvw2Nya/2vza3r5GOS/PYYnrF/V3f3xWP4oiQPze63pcvbj/ckObuq/kMW3wea3LXt/ypdkuTba3EU6Fu6+29H+1qfYTs7r7u/1N0fzeIz4+tWW+qddmF3X727EcY25PDuflOSdPc/dPcXx9MPy+J71p7c3Z9YZaFb9rj5nlTV8Vls3B/T3V+sqndm8UGw7At7mM1tvoSuqu6ZxV6hY7r7k2PX6fI8bxr3t+TWv31l8V/K2/ZS/cs17dyf9dpR55eWhnc8PjBr//bqDjt/Md/uvqivkpzT3S+8wxXeMXuq6R+6+5bdPL8ZVG5f90uT/HJ3nz+WlzP2cU131c79uVuSz3X3o9YY925ZrAu3CWS1OPNgT+vxRlvv8ra79W4z2N37sFnWueXt4S1ZnPe0O1/uc3c/s6q+Kcl3Jrm4qh6VO7n9X7Xu/suqOjqLoz//cxyyTtb+DLvd5Ht4PIvl5fHm3PZUsB2fnbtb564d4z06K/5Jy/15j9pXJfnsCDlfl+S4dUxztywOJybJv0/yZzs9v+PN/XRV3Xtp3N15W5JnVdXdk6Sq/kVV3Wsd0+2q/uuq6mG1uPjhu5fGvzHJfZJk/Hf02br1/KQfSPKurN+7k5xUi3O97jVe50/Hcw+uqseM4e/L7f9Gyy5I8tSqekCSVNX9qupr7kAd63VHanp/kuOr6v7jPTl5BfWswgVJnlZV908Wf8sslpG/Hs+ftjTul5eFib07yXePc4Duk+TJSb6Y5OqqOjn58kU+3zDGf3uS5+yYeHwIbgZr9fMLWWP97O7PJrmxqnas66fs+3L3mj/PrfV/f25dJ9+XxWG3ZHP0b93b0qp6aHe/v7t/Nsmnszg6cWe3/ytVVV+d5Ivd/bokv5jkX9+ByU+uqruNc7m+NotTMmawu+3edUkeMLb790jyXUky9nJfU1UnJUlV3aPGeddJPpdF6P658Y/wyuy3e9SyOI7+zKr6SBYL0vv2MH6y2IA+oqouymIF/d7lJ7v7c1X1qix2G388i98o3ZNXZ7EL+YO1+Pf/hiyu0Lyz9b8gi2Pnn8zifJZ7j/Y3JHlVVT03iwB5WpJfHwvdx5L80DpeM0nS3R+sqrOTXLijD939oVqcqH5FktOq6pVJPprkFbuZz+VV9TNJ3j6C5T8leXaSv1pvLeu0Vk1P3kVN1449oe/N4j+mD+bWwxTT6u7LqurMJO+qqluSfCiLPWi/XVV/ncXy8ZAx+u8neWNVnZjFf/N/utY8N9JYxn4rycVZLA87avz+JK8Yy83ds1iuP5zkuUl+bawPB2YRgJ65r+u+o3bTz12tn8/IYj3+QhbnQP1tNqfnJnlNVf1UFtu8Hf37iSSvq6qfTPIH2Rz9W++29Beq6qgs9tJckMVy+5Hcue3/qn19FvV+KYvt8rOSvHGd016ZRVh9YJJndvc/rKbEO6a7P1NV7xkXDfx9FuFsx3P/VFUvyuIf9auT/MXSpD+Q5JXj+X/K0j/v3X1dVT05yVur6oe7+/2rqN1PSN0BVfX57r73nscE2Puq6t7jvNDU4rurDuvu521wWXvNCDt/391dVadkcWHBiRtdF+sz/oF/S3evN9SxDvvzHjWAzeY7q+qFWWy7/yqLK+62kqOzuCiksji09MMbWw5sPHvUAAAmtT9fTAAAMDVBDQBgUoIaAMCkBDUAgEkJagAAk/r/mSL6Vw0fsqYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "plt.figure(figsize=(10,7))\n",
    "p = sns.countplot(y_train.flatten())\n",
    "p.set(xticklabels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a586fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 3)\n",
    "x_train=x_train / 255.0\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 3)\n",
    "x_test=x_test / 255.0\n",
    "\n",
    "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
    "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffebec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "884b204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1563/1563 [==============================] - 91s 58ms/step - loss: 1.7716 - accuracy: 0.3457 - val_loss: 1.3565 - val_accuracy: 0.5101\n",
      "Epoch 2/20\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 1.3224 - accuracy: 0.5226 - val_loss: 1.1502 - val_accuracy: 0.5945\n",
      "Epoch 3/20\n",
      "1563/1563 [==============================] - 101s 64ms/step - loss: 1.1551 - accuracy: 0.5860 - val_loss: 0.9814 - val_accuracy: 0.6525\n",
      "Epoch 4/20\n",
      "1563/1563 [==============================] - 98s 63ms/step - loss: 1.0281 - accuracy: 0.6360 - val_loss: 0.9627 - val_accuracy: 0.6523\n",
      "Epoch 5/20\n",
      "1563/1563 [==============================] - 87s 56ms/step - loss: 0.9357 - accuracy: 0.6701 - val_loss: 0.8405 - val_accuracy: 0.7057\n",
      "Epoch 6/20\n",
      "1563/1563 [==============================] - 87s 55ms/step - loss: 0.8665 - accuracy: 0.6959 - val_loss: 0.8084 - val_accuracy: 0.7170\n",
      "Epoch 7/20\n",
      "1563/1563 [==============================] - 93s 60ms/step - loss: 0.8161 - accuracy: 0.7147 - val_loss: 0.7730 - val_accuracy: 0.7295\n",
      "Epoch 8/20\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 0.7700 - accuracy: 0.7302 - val_loss: 0.7516 - val_accuracy: 0.7433\n",
      "Epoch 9/20\n",
      "1563/1563 [==============================] - 90s 58ms/step - loss: 0.7361 - accuracy: 0.7398 - val_loss: 0.7254 - val_accuracy: 0.7471\n",
      "Epoch 10/20\n",
      "1563/1563 [==============================] - 91s 58ms/step - loss: 0.7080 - accuracy: 0.7505 - val_loss: 0.6826 - val_accuracy: 0.7694\n",
      "Epoch 11/20\n",
      "1563/1563 [==============================] - 93s 60ms/step - loss: 0.6792 - accuracy: 0.7598 - val_loss: 0.6552 - val_accuracy: 0.7762\n",
      "Epoch 12/20\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 0.6542 - accuracy: 0.7699 - val_loss: 0.6621 - val_accuracy: 0.7755\n",
      "Epoch 13/20\n",
      "1563/1563 [==============================] - 88s 56ms/step - loss: 0.6352 - accuracy: 0.7779 - val_loss: 0.6707 - val_accuracy: 0.7722\n",
      "Epoch 14/20\n",
      "1563/1563 [==============================] - 93s 59ms/step - loss: 0.6174 - accuracy: 0.7834 - val_loss: 0.6585 - val_accuracy: 0.7782\n",
      "Epoch 15/20\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5899 - accuracy: 0.7931 - val_loss: 0.6366 - val_accuracy: 0.7839\n",
      "Epoch 16/20\n",
      "1563/1563 [==============================] - 90s 58ms/step - loss: 0.5796 - accuracy: 0.7954 - val_loss: 0.6628 - val_accuracy: 0.7769\n",
      "Epoch 17/20\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5675 - accuracy: 0.7992 - val_loss: 0.6490 - val_accuracy: 0.7793\n",
      "Epoch 18/20\n",
      "1563/1563 [==============================] - 92s 59ms/step - loss: 0.5511 - accuracy: 0.8067 - val_loss: 0.6337 - val_accuracy: 0.7927\n",
      "Epoch 19/20\n",
      "1563/1563 [==============================] - 89s 57ms/step - loss: 0.5414 - accuracy: 0.8095 - val_loss: 0.6315 - val_accuracy: 0.7874\n",
      "Epoch 20/20\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 0.5234 - accuracy: 0.8148 - val_loss: 0.6272 - val_accuracy: 0.7961\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, 3, padding='same', input_shape=x_train.shape[1:], activation='relu'),\n",
    "    Conv2D(32, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    Conv2D(64, 3, activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "optimizer = GLFGD(learning_rate = 0.004, momentum = 0.94, nesterov = True)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    epochs=epochs, validation_data = (x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
